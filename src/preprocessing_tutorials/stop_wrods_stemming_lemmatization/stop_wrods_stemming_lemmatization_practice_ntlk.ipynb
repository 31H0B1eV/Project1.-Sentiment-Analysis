{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    To an entire generation of filmgoers, it just ...\n",
       "1    Pixar classic is one of the best kids' movies ...\n",
       "2    Apesar de representar um imenso avanço tecnoló...\n",
       "3    When Woody perks up in the opening scene, it's...\n",
       "4    Introduced not one but two indelible character...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data\n",
    "raw_data = pd.read_csv(\"reviews_rt_all.csv\", sep=\"|\")\n",
    "text_data = raw_data['text']\n",
    "text_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize words by getting rid of uppercase\n",
    "txt = text_data.str.lower().str.cat(sep=' ')\n",
    "words = nltk.word_tokenize(txt)\n",
    "# Count word frequency\n",
    "word_dist = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 105164),\n",
       " (',', 99936),\n",
       " ('the', 97231),\n",
       " ('a', 68842),\n",
       " ('of', 59638),\n",
       " ('and', 58935),\n",
       " ('to', 37337),\n",
       " (\"'s\", 35572),\n",
       " ('is', 34932),\n",
       " ('it', 31843),\n",
       " ('in', 25590),\n",
       " ('that', 22234),\n",
       " ('as', 17683),\n",
       " ('but', 16423),\n",
       " ('with', 16064),\n",
       " ('film', 15909),\n",
       " ('this', 15334),\n",
       " ('for', 14499),\n",
       " ('an', 11712),\n",
       " ('its', 10822),\n",
       " ('movie', 10503),\n",
       " ('on', 8854),\n",
       " ('you', 8743),\n",
       " ('one', 8628),\n",
       " (\"n't\", 8350),\n",
       " ('be', 8282),\n",
       " ('...', 8271),\n",
       " ('not', 8132),\n",
       " ('by', 7632),\n",
       " ('are', 7014)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30 most frequent words\n",
    "most_common_words = word_dist.most_common(30)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " ',',\n",
       " 'the',\n",
       " 'a',\n",
       " 'of',\n",
       " 'and',\n",
       " 'to',\n",
       " \"'s\",\n",
       " 'is',\n",
       " 'it',\n",
       " 'in',\n",
       " 'that',\n",
       " 'as',\n",
       " 'but',\n",
       " 'with',\n",
       " 'film',\n",
       " 'this',\n",
       " 'for',\n",
       " 'an',\n",
       " 'its',\n",
       " 'movie',\n",
       " 'on',\n",
       " 'you',\n",
       " 'one',\n",
       " \"n't\",\n",
       " 'be',\n",
       " '...',\n",
       " 'not',\n",
       " 'by',\n",
       " 'are']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define stop words\n",
    "stop_words = [word for (word, freq) in most_common_words]\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('his', 6885),\n",
       " ('at', 6871),\n",
       " ('from', 6609),\n",
       " ('more', 6344),\n",
       " ('has', 6335),\n",
       " ('about', 6190),\n",
       " ('all', 5988),\n",
       " ('than', 5910),\n",
       " ('have', 5467),\n",
       " ('like', 5257),\n",
       " ('i', 5239),\n",
       " ('most', 4698),\n",
       " ('so', 4676),\n",
       " ('if', 4558),\n",
       " ('--', 4549),\n",
       " ('there', 4504),\n",
       " ('comedy', 4308),\n",
       " ('story', 4193),\n",
       " ('or', 4153),\n",
       " ('what', 4005),\n",
       " ('good', 3995),\n",
       " (\"'\", 3943),\n",
       " ('who', 3840),\n",
       " ('just', 3826),\n",
       " ('much', 3728),\n",
       " (\"''\", 3719),\n",
       " ('does', 3685),\n",
       " ('up', 3665),\n",
       " ('``', 3661),\n",
       " ('some', 3545)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete stop words from the entire data \n",
    "cleaned_words = [word for word in words if word not in stop_words]\n",
    "# Just to make sure that stop words were deleted from the words list\n",
    "word_dist = nltk.FreqDist(cleaned_words)\n",
    "most_common_words = word_dist.most_common(30)\n",
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply Porter's stemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmes = [stemmer.stem(w) for w in cleaned_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(w) for w in cleaned_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the different between stemmer and lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lemmas[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizer requires the part of speech to be specified. By default it treats all words as nouns. Let's see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer.stem('doing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize('doing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lemmatizer.lemmatize('doing', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [testenv]",
   "language": "python",
   "name": "Python [testenv]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
